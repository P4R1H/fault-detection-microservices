#!/usr/bin/env python3
"""
Test all encoders with real RCAEval dataset.

This script:
1. Loads a few failure cases from local dataset
2. Preprocesses metrics/logs/traces
3. Tests each encoder (Chronos, TCN, GCN)
4. Validates output shapes and functionality
5. Reports any errors

Run with: python scripts/test_encoders.py --n_cases 5
"""

import sys
import os
import argparse
import torch
import numpy as np
import pandas as pd
from pathlib import Path

# Add project to path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.data.loader import RCAEvalDataLoader
from src.data.preprocessing import (
    MetricsPreprocessor,
    LogsPreprocessor,
    TracesPreprocessor,
    preprocess_failure_case
)
from src.encoders.metrics_encoder import ChronosEncoder, TCNEncoder, create_metrics_encoder
from src.encoders.traces_encoder import GCNEncoder, GATEncoder, create_trace_encoder


def test_data_loading(data_path: str, n_cases: int = 5):
    """Test data loading from RCAEval."""
    print("\n" + "="*70)
    print("STEP 1: Testing Data Loading")
    print("="*70)

    try:
        loader = RCAEvalDataLoader(data_path)
        print(f"âœ“ Data loader initialized")

        # Load cases
        all_cases = loader.load_all_cases()
        print(f"âœ“ Found {len(all_cases)} total failure cases")

        # Get train split
        train_cases, val_cases, test_cases = loader.load_splits()
        print(f"âœ“ Splits: {len(train_cases)} train, {len(val_cases)} val, {len(test_cases)} test")

        # Test loading a few cases
        test_cases = all_cases[:n_cases]
        print(f"\n Testing with {n_cases} cases:")

        for i, case in enumerate(test_cases):
            print(f"\n  Case {i+1}:")
            print(f"    - ID: {case.case_id}")
            print(f"    - System: {case.system}")
            print(f"    - Fault: {case.fault_type}")
            print(f"    - Root cause: {case.root_cause_service}")

            # Load data
            case.load_data(metrics=True, logs=True, traces=True)

            if case.metrics is not None:
                print(f"    - Metrics: {case.metrics.shape}")
            if case.logs is not None:
                print(f"    - Logs: {len(case.logs)} lines")
            if case.traces is not None:
                print(f"    - Traces: {len(case.traces)} spans")

            case.unload_data()

        return test_cases

    except Exception as e:
        print(f"âœ— Data loading failed: {e}")
        import traceback
        traceback.print_exc()
        return None


def test_metrics_preprocessing(cases):
    """Test metrics preprocessing pipeline."""
    print("\n" + "="*70)
    print("STEP 2: Testing Metrics Preprocessing")
    print("="*70)

    try:
        # Initialize preprocessor
        preprocessor = MetricsPreprocessor(
            window_size=12,
            normalization='zscore',
            fill_method='forward',
            clip_outliers=True
        )
        print("âœ“ MetricsPreprocessor initialized")

        # Load and preprocess first case
        case = cases[0]
        case.load_data(metrics=True)

        if case.metrics is None:
            print("âœ— No metrics data available")
            return None

        print(f"\n  Raw metrics shape: {case.metrics.shape}")

        # Fit on training data
        preprocessor.fit(case.metrics)
        print("âœ“ Preprocessor fitted")

        # Transform
        processed = preprocessor.transform(case.metrics)
        print(f"âœ“ Processed shape: {processed.shape}")

        # Create windows
        windows = preprocessor.create_windows(processed)
        print(f"âœ“ Windows shape: {windows.shape}")
        print(f"  (n_windows={windows.shape[0]}, window_size={windows.shape[1]}, n_features={windows.shape[2]})")

        case.unload_data()
        return preprocessor, windows

    except Exception as e:
        print(f"âœ— Metrics preprocessing failed: {e}")
        import traceback
        traceback.print_exc()
        return None, None


def test_chronos_encoder(windows):
    """Test Chronos-Bolt-Tiny encoder."""
    print("\n" + "="*70)
    print("STEP 3: Testing Chronos-Bolt-Tiny Encoder")
    print("="*70)

    try:
        # Convert to tensor
        x = torch.FloatTensor(windows[:5])  # Test with 5 windows
        print(f"  Input shape: {x.shape}")

        # Create encoder
        try:
            encoder = ChronosEncoder(
                embedding_dim=256,
                context_length=min(512, x.shape[1]),
                prediction_length=64,
                freeze_backbone=True,
                device='cpu'  # Use CPU for testing
            )
            print("âœ“ ChronosEncoder initialized")
        except ImportError as ie:
            print(f"âš  Chronos not installed, skipping: {ie}")
            return None

        # Forward pass
        encoder.eval()
        with torch.no_grad():
            embeddings = encoder(x)

        print(f"âœ“ Forward pass successful")
        print(f"âœ“ Output shape: {embeddings.shape}")
        print(f"  Expected: (batch_size={x.shape[0]}, embedding_dim=256)")

        # Test anomaly scoring
        anomaly_scores = encoder.get_anomaly_score(x)
        print(f"âœ“ Anomaly scores shape: {anomaly_scores.shape}")
        print(f"  Scores: {anomaly_scores.numpy()}")

        return embeddings

    except Exception as e:
        print(f"âœ— Chronos encoder failed: {e}")
        import traceback
        traceback.print_exc()
        return None


def test_tcn_encoder(windows):
    """Test TCN encoder."""
    print("\n" + "="*70)
    print("STEP 4: Testing TCN Encoder")
    print("="*70)

    try:
        # Convert to tensor
        x = torch.FloatTensor(windows[:5])  # Test with 5 windows
        print(f"  Input shape: {x.shape}")

        # Create encoder
        encoder = TCNEncoder(
            in_channels=x.shape[2],  # Number of features
            hidden_channels=64,
            embedding_dim=256,
            num_layers=7,
            dropout=0.3
        )
        print(f"âœ“ TCNEncoder initialized")
        print(f"  Receptive field: {encoder.receptive_field} timesteps")

        # Forward pass
        encoder.eval()
        with torch.no_grad():
            embeddings = encoder(x)

        print(f"âœ“ Forward pass successful")
        print(f"âœ“ Output shape: {embeddings.shape}")
        print(f"  Expected: (batch_size={x.shape[0]}, embedding_dim=256)")

        # Count parameters
        n_params = sum(p.numel() for p in encoder.parameters())
        print(f"  Total parameters: {n_params:,} (~{n_params/1e6:.1f}M)")

        return embeddings

    except Exception as e:
        print(f"âœ— TCN encoder failed: {e}")
        import traceback
        traceback.print_exc()
        return None


def test_traces_preprocessing(cases):
    """Test traces preprocessing."""
    print("\n" + "="*70)
    print("STEP 5: Testing Traces Preprocessing")
    print("="*70)

    try:
        preprocessor = TracesPreprocessor()
        print("âœ“ TracesPreprocessor initialized")

        # Load traces from first case
        case = cases[0]
        case.load_data(traces=True)

        if case.traces is None:
            print("âœ— No traces data available")
            return None, None

        print(f"\n  Raw traces: {len(case.traces)} spans")

        # Build service graph
        edge_index, service_mapping = preprocessor.build_service_graph(
            case.traces,
            parent_col='parentService',
            child_col='serviceName'
        )

        print(f"âœ“ Service graph built")
        print(f"  Services: {len(service_mapping)}")
        print(f"  Edges: {edge_index.shape[1]}")
        print(f"  Service names: {list(service_mapping.keys())[:10]}...")

        # Extract node features
        node_features = preprocessor.extract_node_features(
            case.traces,
            service_col='serviceName',
            latency_col='duration',
            error_col=None
        )

        print(f"âœ“ Node features extracted")
        print(f"  Shape: {node_features.shape}")
        print(f"  Columns: {list(node_features.columns)}")

        case.unload_data()

        return edge_index, node_features, service_mapping

    except Exception as e:
        print(f"âœ— Traces preprocessing failed: {e}")
        import traceback
        traceback.print_exc()
        return None, None, None


def test_gcn_encoder(edge_index, node_features):
    """Test GCN encoder."""
    print("\n" + "="*70)
    print("STEP 6: Testing GCN Encoder")
    print("="*70)

    try:
        # Prepare data
        numeric_cols = node_features.select_dtypes(include=[np.number]).columns
        node_feats = torch.FloatTensor(node_features[numeric_cols].values)
        edge_idx = torch.LongTensor(edge_index)

        print(f"  Node features shape: {node_feats.shape}")
        print(f"  Edge index shape: {edge_idx.shape}")

        # Create encoder
        try:
            encoder = GCNEncoder(
                in_channels=node_feats.shape[1],
                hidden_channels=64,
                embedding_dim=128,
                num_layers=2,
                dropout=0.3
            )
            print("âœ“ GCNEncoder initialized")
        except ImportError as ie:
            print(f"âš  PyTorch Geometric not installed, skipping: {ie}")
            return None

        # Forward pass (node-level embeddings)
        encoder.eval()
        with torch.no_grad():
            node_embeddings = encoder.get_node_embeddings(node_feats, edge_idx)

        print(f"âœ“ Forward pass successful")
        print(f"âœ“ Node embeddings shape: {node_embeddings.shape}")
        print(f"  Expected: (num_nodes={node_feats.shape[0]}, embedding_dim=128)")

        # Count parameters
        n_params = sum(p.numel() for p in encoder.parameters())
        print(f"  Total parameters: {n_params:,} (~{n_params/1e6:.2f}M)")

        return node_embeddings

    except Exception as e:
        print(f"âœ— GCN encoder failed: {e}")
        import traceback
        traceback.print_exc()
        return None


def main():
    parser = argparse.ArgumentParser(description='Test encoders with RCAEval dataset')
    parser.add_argument('--data_path', default='data/RCAEval', help='Path to dataset')
    parser.add_argument('--n_cases', type=int, default=5, help='Number of cases to test')
    args = parser.parse_args()

    print("="*70)
    print("ENCODER TESTING SUITE")
    print("="*70)
    print(f"Dataset: {args.data_path}")
    print(f"Test cases: {args.n_cases}")

    # Check if dataset exists
    if not os.path.exists(args.data_path):
        print(f"\nâœ— Dataset not found at {args.data_path}")
        print("  Please ensure RCAEval dataset is extracted to data/RCAEval/")
        return 1

    # Run tests
    cases = test_data_loading(args.data_path, args.n_cases)
    if cases is None:
        return 1

    preprocessor, windows = test_metrics_preprocessing(cases)
    if windows is None:
        return 1

    # Test encoders
    chronos_emb = test_chronos_encoder(windows)
    tcn_emb = test_tcn_encoder(windows)

    # Test traces
    edge_index, node_features, service_mapping = test_traces_preprocessing(cases)
    if edge_index is not None:
        gcn_emb = test_gcn_encoder(edge_index, node_features)

    # Summary
    print("\n" + "="*70)
    print("SUMMARY")
    print("="*70)
    print(f"âœ“ Data loading: PASSED")
    print(f"âœ“ Metrics preprocessing: PASSED")
    print(f"âœ“ Chronos encoder: {'PASSED' if chronos_emb is not None else 'SKIPPED (not installed)'}")
    print(f"âœ“ TCN encoder: {'PASSED' if tcn_emb is not None else 'FAILED'}")
    print(f"âœ“ Traces preprocessing: {'PASSED' if edge_index is not None else 'FAILED'}")
    print(f"âœ“ GCN encoder: {'PASSED' if edge_index is not None else 'SKIPPED (PyG not installed)'}")

    print("\nðŸŽ‰ All available encoders tested successfully!")
    print("\nNext steps:")
    print("  1. Install missing dependencies if needed:")
    print("     pip install chronos-forecasting>=1.0.0")
    print("     pip install torch-geometric")
    print("  2. Proceed with Phase 7-8 implementation (PCMCI, Fusion)")
    print("  3. Build end-to-end RCA pipeline")

    return 0


if __name__ == '__main__':
    sys.exit(main())
